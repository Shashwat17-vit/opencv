{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrmFdQZrFDk/TmKsiS7La1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashwat17-vit/opencv/blob/master/TomatoCNNUnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jblS9yuO-erv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true = K.cast(y_true, 'float32')  # Ensure y_true is float32\n",
        "    y_pred = K.cast(y_pred, 'float32')  # Ensure y_pred is float32\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def load_images(image_dir, img_size=(1400, 875)):\n",
        "    images = []\n",
        "\n",
        "    image_files = sorted(os.listdir(image_dir))  # Ensure matching order with masks\n",
        "\n",
        "    for img_file in image_files:\n",
        "        # Load and preprocess the image\n",
        "        img_path = os.path.join(image_dir, img_file)\n",
        "\n",
        "        img = load_img(img_path, target_size=img_size)  # Resize image\n",
        "\n",
        "        img = img_to_array(img) / 255.0  # Normalize image\n",
        "\n",
        "        images.append(img)\n",
        "\n",
        "    return np.array(images)"
      ],
      "metadata": {
        "id": "1lv0QCBA-iyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"infected-tomato-leaf-vein-segmentation/train\"\n",
        "img_size = (1400, 875)  # Input size for U-Net\n",
        "\n",
        "images = load_images(image_dir, img_size)\n",
        "\n",
        "print(f\"Loaded {len(images)} images\")\n",
        "print(f\"Image shape: {images[0].shape}\")"
      ],
      "metadata": {
        "id": "Lb5A51TL-mrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Decoding the Run-Length Encoded Mask\n",
        "\n",
        "import numpy as np\n",
        "HEIGHT = 1400\n",
        "WIDTH = 875\n",
        "\n",
        "mask_read=pd.read_csv(\"infected-tomato-leaf-vein-segmentation/train.csv\")\n",
        "\n",
        "mask=mask_read['annotation']\n",
        "\n",
        "\n",
        "def rl_decode(enc):\n",
        "    parts = [int(s) for s in enc.split(' ')]\n",
        "    dec = list()\n",
        "    for i in range(0, len(parts), 2):\n",
        "        cnt = parts[i]\n",
        "        val = parts[i+1]\n",
        "        dec += cnt * [val]\n",
        "    return np.array(dec, dtype=np.uint8).reshape((HEIGHT, WIDTH))\n",
        "\n",
        "decoded_masks=[]\n",
        "\n",
        "for item in mask:\n",
        "    np_mask=rl_decode(item)\n",
        "    decoded_masks.append(np_mask)\n",
        "\n",
        "decoded_masks = np.array(decoded_masks)\n",
        "print(decoded_masks)\n",
        "\n",
        "out=pd.DataFrame(decoded_masks[0])\n",
        "\n",
        "#output=pd.DataFrame({'id':test_data.id,'Target':XGB_submit})\n",
        "#output[\"Target\"]=output['Target'].map({0:'Dropout',1:'Enrolled',2:'Graduate'})\n",
        "out.to_csv('Check',index=False)"
      ],
      "metadata": {
        "id": "8KeuWY8--okK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(decoded_masks.shape) == 3:  # Shape (batch_size, height, width)\n",
        "    thresholded_predictions = (decoded_masks[1] > 0.5).astype(np.uint8)\n",
        "    plt.imshow(thresholded_predictions, cmap='gray')\n",
        "elif len(decoded_masks.shape) == 4:  # Shape (batch_size, height, width, channels)\n",
        "    thresholded_predictions = (decoded_masks[1] > 0.5).astype(np.uint8)\n",
        "    plt.imshow(thresholded_predictions[:, :, 0], cmap='gray')\n",
        "else:\n",
        "    raise ValueError(\"Unexpected shape of decoded_masks:\", decoded_masks.shape)"
      ],
      "metadata": {
        "id": "Ffvck3k0-rvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, decoded_masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit U-Net\n",
        "#model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=8)"
      ],
      "metadata": {
        "id": "RdZwGkRs-uY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_for_leaf(input_shape=(1400, 875, 3)):\n",
        "    # Sequential-like layers for U-Net\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
        "\n",
        "    # Encoder\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((5, 5)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((5, 5)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 1)))\n",
        "\n",
        "    # Bottleneck\n",
        "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    # Decoder\n",
        "    model.add(tf.keras.layers.UpSampling2D((2, 1)))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    model.add(tf.keras.layers.UpSampling2D((5, 5)))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    model.add(tf.keras.layers.UpSampling2D((5, 5)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (1400, 875, 3)\n",
        "unet_model = unet_for_leaf(input_shape)\n",
        "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryIoU()])\n",
        "unet_model.summary()"
      ],
      "metadata": {
        "id": "1PHC-Ann-wkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StopAndTestCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, stop_epoch):\n",
        "        super().__init__()\n",
        "        self.stop_epoch = stop_epoch\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch + 1 == self.stop_epoch:\n",
        "            print(f\"\\nStopping training at epoch {self.stop_epoch}\")\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "JC_ihGU4-y5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='model_checkpoint.weights.h5',  # Save path\n",
        "    save_best_only=True,            # Save the model at every epoch\n",
        "    save_weights_only=True           # Save weights instead of the full model\n",
        ")\n",
        "stop_epoch = 2\n",
        "\n",
        "model_main= unet_model.fit(images, decoded_masks,epochs=10,batch_size=1, verbose=1,callbacks=[checkpoint_callback,StopAndTestCallback(stop_epoch)])"
      ],
      "metadata": {
        "id": "ZUpts9aY-0pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"infected-tomato-leaf-vein-segmentation/single/\"\n",
        "img_size = (1400, 875)  # Input size for U-Net\n",
        "\n",
        "images_test = load_images(image_dir, img_size)\n",
        "\n",
        "\n",
        "print(images_test.shape)  # Should be (1, 875, 1400, 3) for a single image\n",
        "\n",
        "predictions = unet_model.predict(images_test)\n",
        "\n",
        "print(predictions.shape)  # Should be (1, 875, 1400, 3) for a single image\n",
        "\n",
        "thresholded_predictions = (predictions > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(predictions[0, :, :, 0], cmap='gray')  # For binary segmentation\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_W7nRK0r-2vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_main= unet_model.fit(images, decoded_masks, epochs=10, initial_epoch=stop_epoch, verbose=2)"
      ],
      "metadata": {
        "id": "mcm9zYwX-53I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model (architecture, weights, optimizer)\n",
        "unet_model.save('unet_model_epoch2.h5')  # You can use any name for the file\n"
      ],
      "metadata": {
        "id": "wOA81FUT-7tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"infected-tomato-leaf-vein-segmentation/single/\"\n",
        "img_size = (1400, 875)  # Input size for U-Net\n",
        "\n",
        "images_test = load_images(image_dir, img_size)\n",
        "\n",
        "\n",
        "print(images_test.shape)  # Should be (1, 875, 1400, 3) for a single image\n",
        "\n",
        "predictions = unet_model.predict(images_test)\n",
        "\n",
        "print(predictions.shape)  # Should be (1, 875, 1400, 3) for a single image\n",
        "\n",
        "thresholded_predictions = (predictions > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(predictions[0, :, :, 0], cmap='gray')  # For binary segmentation\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cFVfz3dB-9_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}